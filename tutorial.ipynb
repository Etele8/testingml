{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLOv5 Tutorial",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6MPjfT5NrKQ"
      },
      "source": [
        "<div align=\"center\">\n",
        "\n",
        "  <a href=\"https://ultralytics.com/yolov5\" target=\"_blank\">\n",
        "    <img width=\"1024\", src=\"https://raw.githubusercontent.com/ultralytics/assets/main/yolov5/v70/splash.png\"></a>\n",
        "\n",
        "[‰∏≠Êñá](https://docs.ultralytics.com/zh/) | [ÌïúÍµ≠Ïñ¥](https://docs.ultralytics.com/ko/) | [Êó•Êú¨Ë™û](https://docs.ultralytics.com/ja/) | [–†—É—Å—Å–∫–∏–π](https://docs.ultralytics.com/ru/) | [Deutsch](https://docs.ultralytics.com/de/) | [Fran√ßais](https://docs.ultralytics.com/fr/) | [Espa√±ol](https://docs.ultralytics.com/es/) | [Portugu√™s](https://docs.ultralytics.com/pt/) | [ÿßŸÑÿπÿ±ÿ®Ÿäÿ©](https://docs.ultralytics.com/ar/)\n",
        "\n",
        "  <a href=\"https://bit.ly/yolov5-paperspace-notebook\"><img src=\"https://assets.paperspace.io/img/gradient-badge.svg\" alt=\"Run on Gradient\"></a>\n",
        "  <a href=\"https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
        "  <a href=\"https://www.kaggle.com/models/ultralytics/yolov5\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open In Kaggle\"></a>\n",
        "\n",
        "This <a href=\"https://github.com/ultralytics/yolov5\">YOLOv5</a> üöÄ notebook by <a href=\"https://ultralytics.com\">Ultralytics</a> presents simple train, validate and predict examples to help start your AI adventure.<br>We hope that the resources in this notebook will help you get the most out of YOLOv5. Please browse the YOLOv5 <a href=\"https://docs.ultralytics.com/yolov5\">Docs</a> for details, raise an issue on <a href=\"https://github.com/ultralytics/yolov5\">GitHub</a> for support, and join our <a href=\"https://ultralytics.com/discord\">Discord</a> community for questions and discussions!\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "# Setup\n",
        "\n",
        "Clone GitHub [repository](https://github.com/ultralytics/yolov5), install [dependencies](https://github.com/ultralytics/yolov5/blob/master/requirements.txt) and check PyTorch and GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbvMlHd_QwMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82073fc3-e369-463e-ad55-f227b10fb0e0"
      },
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt comet_ml  # install\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()  # checks"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 üöÄ v7.0-408-g3fee72b5 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete ‚úÖ (2 CPUs, 12.7 GB RAM, 41.3/112.6 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Verify files (replace with your path)\n",
        "!ls \"/content/drive/MyDrive/annotated_imgs\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbPtTFKn9Y4R",
        "outputId": "37e6d467-dc13-4c31-81c8-10b72266109a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "K1_msz.png  K3_msz.png\tK4_msz.png  T9_msz.png\tZ9_msz.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from skimage.segmentation import watershed\n",
        "from skimage.feature import peak_local_max\n",
        "from scipy import ndimage\n",
        "\n",
        "# Create directories if they don't exist\n",
        "!mkdir -p \"/content/drive/MyDrive/dataset/precise_labels\"\n",
        "!mkdir -p \"/content/drive/MyDrive/dataset/visualizations\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfvvALIQYWkS",
        "outputId": "e70094ea-7cb0-4e14-c0b7-8585caff3bce"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== MOUNT DRIVE & IMPORTS ==========\n",
        "from google.colab import drive\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from skimage.segmentation import watershed\n",
        "from skimage.feature import peak_local_max\n",
        "from scipy import ndimage\n",
        "import re\n",
        "\n",
        "# ========== CONFIGURATION ==========\n",
        "ANNOTATED_DIR = Path(\"/content/drive/MyDrive/annotated_imgs\")\n",
        "ORIGINAL_DIR = Path(\"/content/drive/MyDrive/dataset/originals\")\n",
        "OUTPUT_DIR = Path(\"/content/drive/MyDrive/dataset/precise_labels\")\n",
        "VISUAL_DIR = Path(\"/content/drive/MyDrive/dataset/visualizations\")\n",
        "\n",
        "# ========== SAFE SEGMENTATION PARAMETERS ==========\n",
        "INITIAL_HUE_TOLERANCE = 15\n",
        "INITIAL_SAT_TOLERANCE = 25\n",
        "MIN_BACTERIA_AREA = 50\n",
        "MAX_BACTERIA_AREA = 2000\n",
        "\n",
        "# ========== BULLETPROOF CORE FUNCTIONS ==========\n",
        "def safe_resize(img, target_width, target_height):\n",
        "    \"\"\"Guaranteed safe resize with coordinate preservation\"\"\"\n",
        "    if img.size == 0:\n",
        "        return np.zeros((target_height, target_width, 3), np.zeros((target_height, target_width), np.uint8)\n",
        "    return cv2.resize(img, (target_width, target_height), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "def adaptive_region_growing(annot_img, orig_img):\n",
        "    # Get original dimensions first\n",
        "    orig_height, orig_width = orig_img.shape[:2]\n",
        "\n",
        "    # Resize annotation to match original dimensions\n",
        "    annot_img = safe_resize(annot_img, orig_width, orig_height)\n",
        "\n",
        "    # Convert to HSV space\n",
        "    hsv = cv2.cvtColor(orig_img, cv2.COLOR_BGR2HSV)\n",
        "    annot_hsv = cv2.cvtColor(annot_img, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # Detect blue annotations with triple validation\n",
        "    blue_mask = cv2.inRange(annot_hsv, np.array([90,70,70]), np.array([130,255,255]))\n",
        "    blue_mask = cv2.morphologyEx(blue_mask, cv2.MORPH_CLOSE, np.ones((5,5), np.uint8))\n",
        "\n",
        "    # Safe contour detection\n",
        "    contours, _ = cv2.findContours(blue_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    annotations = []\n",
        "    for cnt in contours:\n",
        "        M = cv2.moments(cnt)\n",
        "        if M[\"m00\"] > 0:\n",
        "            cX = np.clip(int(M[\"m10\"]/M[\"m00\"]), 0, orig_width-1)\n",
        "            cY = np.clip(int(M[\"m01\"]/M[\"m00\"]), 0, orig_height-1)\n",
        "            annotations.append((cX, cY))\n",
        "\n",
        "    # Create background mask with validation\n",
        "    _, bg_mask = cv2.threshold(hsv[:,:,2], 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
        "    bg_mask = (bg_mask == 0).astype(np.uint8)\n",
        "\n",
        "    # Region growing with boundary armor\n",
        "    final_mask = np.zeros_like(hsv[:,:,0], dtype=np.uint8)\n",
        "    for seed in annotations:\n",
        "        x, y = np.clip(seed[0], 0, orig_width-1), np.clip(seed[1], 0, orig_height-1)\n",
        "        best_seed = relocate_seed((x, y), hsv, bg_mask, (orig_width, orig_height))\n",
        "\n",
        "        # Guard against invalid seeds\n",
        "        if not (0 <= best_seed[0] < orig_width and 0 <= best_seed[1] < orig_height):\n",
        "            continue\n",
        "\n",
        "        # Region growing core\n",
        "        h_ref, s_ref, _ = hsv[best_seed[1], best_seed[0]]\n",
        "        region = np.zeros_like(final_mask)\n",
        "        queue = [best_seed]\n",
        "        visited = set()\n",
        "\n",
        "        while queue:\n",
        "            x, y = queue.pop(0)\n",
        "            x = np.clip(x, 0, orig_width-1)\n",
        "            y = np.clip(y, 0, orig_height-1)\n",
        "\n",
        "            if (x, y) in visited: continue\n",
        "            if bg_mask[y, x]: continue\n",
        "\n",
        "            # Color similarity check with safety\n",
        "            h, s, _ = hsv[y, x]\n",
        "            if abs(int(h)-h_ref) < INITIAL_HUE_TOLERANCE and abs(int(s)-s_ref) < INITIAL_SAT_TOLERANCE:\n",
        "                region[y, x] = 1\n",
        "                visited.add((x, y))\n",
        "\n",
        "                # Neighbor expansion with boundary armor\n",
        "                for dx in [-1, 0, 1]:\n",
        "                    for dy in [-1, 0, 1]:\n",
        "                        nx = np.clip(x + dx, 0, orig_width-1)\n",
        "                        ny = np.clip(y + dy, 0, orig_height-1)\n",
        "                        queue.append((nx, ny))\n",
        "\n",
        "        final_mask = cv2.bitwise_or(final_mask, region)\n",
        "\n",
        "    # Post-processing fortress\n",
        "    final_mask = cv2.morphologyEx(final_mask, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7,7)))\n",
        "\n",
        "    # Watershed with coordinate validation\n",
        "    distance = ndimage.distance_transform_edt(final_mask)\n",
        "    coords = peak_local_max(distance, min_distance=20, labels=final_mask)\n",
        "\n",
        "    # Validate coordinates before marker creation\n",
        "    valid_coords = []\n",
        "    for y, x in coords:\n",
        "        if 0 <= x < orig_width and 0 <= y < orig_height:\n",
        "            valid_coords.append((x, y))\n",
        "\n",
        "    markers = np.zeros_like(final_mask, dtype=np.int32)\n",
        "    for i, (x, y) in enumerate(valid_coords):\n",
        "        markers[y, x] = i + 1\n",
        "\n",
        "    labels = watershed(-distance, markers, mask=final_mask)\n",
        "\n",
        "    # Extract contours with boundary checks\n",
        "    bacteria_contours = []\n",
        "    for label in np.unique(labels):\n",
        "        if label == 0: continue\n",
        "\n",
        "        mask = np.zeros_like(labels, dtype=np.uint8)\n",
        "        mask[labels == label] = 255\n",
        "\n",
        "        cnts, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        for cnt in cnts:\n",
        "            area = cv2.contourArea(cnt)\n",
        "            if MIN_BACTERIA_AREA < area < MAX_BACTERIA_AREA:\n",
        "                bacteria_contours.append(cnt)\n",
        "\n",
        "    return bacteria_contours\n",
        "\n",
        "def relocate_seed(original_seed, hsv_img, bg_mask, img_size):\n",
        "    orig_width, orig_height = img_size\n",
        "    x, y = np.clip(original_seed[0], 0, orig_width-1), np.clip(original_seed[1], 0, orig_height-1)\n",
        "    best_score = -np.inf\n",
        "    best_pos = (x, y)\n",
        "\n",
        "    for dx in range(-7, 8):\n",
        "        for dy in range(-7, 8):\n",
        "            nx = np.clip(x + dx, 0, orig_width-1)\n",
        "            ny = np.clip(y + dy, 0, orig_height-1)\n",
        "\n",
        "            if bg_mask[ny, nx]: continue\n",
        "\n",
        "            # Safe window extraction\n",
        "            y1, y2 = max(0, ny-5), min(ny+6, orig_height)\n",
        "            x1, x2 = max(0, nx-5), min(nx+6, orig_width)\n",
        "            window = hsv_img[y1:y2, x1:x2]\n",
        "\n",
        "            if window.size == 0: continue\n",
        "\n",
        "            std_dev = np.std(window, axis=(0,1))\n",
        "            score = std_dev[0] + std_dev[1]\n",
        "\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_pos = (nx, ny)\n",
        "\n",
        "    return best_pos\n",
        "\n",
        "def process_image_pair(annot_path, orig_path):\n",
        "    # Load images\n",
        "    annot_img = cv2.imread(str(annot_path))\n",
        "    orig_img = cv2.imread(str(orig_path))\n",
        "\n",
        "    if annot_img is None or orig_img is None:\n",
        "        print(f\"‚ö†Ô∏è Error loading {annot_path.name} or {orig_path.name}\")\n",
        "        return\n",
        "\n",
        "    # Perform segmentation\n",
        "    contours = adaptive_region_growing(annot_img, orig_img)\n",
        "\n",
        "    # Create visualization\n",
        "    display_img = orig_img.copy()\n",
        "\n",
        "    # Draw filled contours with transparency\n",
        "    overlay = display_img.copy()\n",
        "    cv2.drawContours(overlay, contours, -1, (0,255,0), -1)  # Green fill\n",
        "    cv2.addWeighted(overlay, 0.3, display_img, 0.7, 0, display_img)\n",
        "\n",
        "    # Draw contour edges\n",
        "    cv2.drawContours(display_img, contours, -1, (255,0,0), 2)  # Blue edges\n",
        "\n",
        "    # Create comparison figure\n",
        "    fig, ax = plt.subplots(1, 3, figsize=(20, 6))\n",
        "    fig.suptitle(f\"Analysis for {orig_path.name}\", fontsize=16, y=0.95)\n",
        "\n",
        "    # Original Image\n",
        "    ax[0].imshow(cv2.cvtColor(orig_img, cv2.COLOR_BGR2RGB))\n",
        "    ax[0].set_title(\"Original Image\\n\", fontsize=12)\n",
        "    ax[0].axis('off')\n",
        "\n",
        "    # Annotation Points\n",
        "    blue_mask = cv2.inRange(cv2.cvtColor(annot_img, cv2.COLOR_BGR2HSV),\n",
        "                           np.array([90,70,70]), np.array([130,255,255]))\n",
        "    ax[1].imshow(blue_mask, cmap='Blues')\n",
        "    ax[1].set_title(f\"Annotation Points: {len(contours)}\\n\", fontsize=12)\n",
        "    ax[1].axis('off')\n",
        "\n",
        "    # Segmentation Result\n",
        "    ax[2].imshow(cv2.cvtColor(display_img, cv2.COLOR_BGR2RGB))\n",
        "    ax[2].set_title(f\"Segmented Bacteria: {len(contours)}\\n\", fontsize=12)\n",
        "    ax[2].axis('off')\n",
        "\n",
        "    plt.savefig(VISUAL_DIR / f\"{orig_path.stem}_seg.png\", bbox_inches='tight', dpi=150)\n",
        "    plt.close()\n",
        "\n",
        "    # Save labels\n",
        "    save_yolo_labels(orig_img.shape, contours, orig_path.stem)\n",
        "\n",
        "def save_yolo_labels(img_shape, contours, stem):\n",
        "    height, width = img_shape[:2]\n",
        "    with open(OUTPUT_DIR / f\"{stem}.txt\", \"w\") as f:\n",
        "        for cnt in contours:\n",
        "            # Get rotated bounding box\n",
        "            rect = cv2.minAreaRect(cnt)\n",
        "            box = cv2.boxPoints(rect)\n",
        "            box_norm = box / np.array([width, height])\n",
        "\n",
        "            # YOLO OBB format: class x1 y1 x2 y2 x3 y3 x4 y4\n",
        "            line = f\"0 \" + \" \".join([f\"{p[0]:.6f} {p[1]:.6f}\" for p in box_norm])\n",
        "            f.write(line + \"\\n\")\n",
        "\n",
        "def find_matching_pairs(annotated_dir, original_dir):\n",
        "    \"\"\"Matches any files with pattern: <name>_msz.<ext> to <name>.<ext>\"\"\"\n",
        "    pattern = re.compile(r'^(.+)_msz(\\.[a-zA-Z]+)$', re.IGNORECASE)\n",
        "    pairs = []\n",
        "\n",
        "    for annot_path in annotated_dir.glob('*'):\n",
        "        match = pattern.match(annot_path.name)\n",
        "        if match:\n",
        "            base_name = match.group(1) + match.group(2)\n",
        "            orig_path = original_dir / base_name\n",
        "            if orig_path.exists():\n",
        "                pairs.append((annot_path, orig_path))\n",
        "            else:\n",
        "                print(f\"‚ö†Ô∏è Missing original for {annot_path.name}\")\n",
        "    return pairs\n",
        "\n",
        "def main():\n",
        "    # Setup directories\n",
        "    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    VISUAL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Find all valid image pairs\n",
        "    pairs = find_matching_pairs(ANNOTATED_DIR, ORIGINAL_DIR)\n",
        "\n",
        "    if not pairs:\n",
        "        print(\"‚ùå No valid image pairs found!\")\n",
        "        print(\"Ensure annotated files follow <name>_msz.<ext> pattern\")\n",
        "        return\n",
        "\n",
        "    processed = 0\n",
        "    for annot_path, orig_path in pairs:\n",
        "        try:\n",
        "            process_image_pair(annot_path, orig_path)\n",
        "            processed += 1\n",
        "            print(f\"‚úÖ Processed {orig_path.name}\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error processing {orig_path.name}: {str(e)}\")\n",
        "\n",
        "    print(f\"\\nüéâ Finished! Processed {processed}/{len(pairs)} image pairs\")\n",
        "    print(f\"Labels saved to: {OUTPUT_DIR}\")\n",
        "    print(f\"Visualizations saved to: {VISUAL_DIR}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Clear previous outputs (optional)\n",
        "    !rm -rf \"/content/drive/MyDrive/dataset/precise_labels/*\"\n",
        "    !rm -rf \"/content/drive/MyDrive/dataset/visualizations/*\"\n",
        "\n",
        "    # Run the processing\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Br9EymrcYXip",
        "outputId": "1bfff8ca-8543-4d82-f75d-cc37f31c2b3c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "‚ùå Error processing K4.png: index 1774 is out of bounds for axis 0 with size 1536\n",
            "‚ùå Error processing T9.png: index 1827 is out of bounds for axis 0 with size 1536\n",
            "‚ùå Error processing K1.png: index 1652 is out of bounds for axis 0 with size 1536\n",
            "‚ùå Error processing Z9.png: index 1682 is out of bounds for axis 0 with size 1536\n",
            "‚ùå Error processing K3.png: index 1798 is out of bounds for axis 0 with size 1536\n",
            "\n",
            "üéâ Finished! Processed 0/5 image pairs\n",
            "Labels saved to: /content/drive/MyDrive/dataset/precise_labels\n",
            "Visualizations saved to: /content/drive/MyDrive/dataset/visualizations\n"
          ]
        }
      ]
    }
  ]
}