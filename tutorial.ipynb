{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLOv5 Tutorial",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6MPjfT5NrKQ"
      },
      "source": [
        "<div align=\"center\">\n",
        "\n",
        "  <a href=\"https://ultralytics.com/yolov5\" target=\"_blank\">\n",
        "    <img width=\"1024\", src=\"https://raw.githubusercontent.com/ultralytics/assets/main/yolov5/v70/splash.png\"></a>\n",
        "\n",
        "[‰∏≠Êñá](https://docs.ultralytics.com/zh/) | [ÌïúÍµ≠Ïñ¥](https://docs.ultralytics.com/ko/) | [Êó•Êú¨Ë™û](https://docs.ultralytics.com/ja/) | [–†—É—Å—Å–∫–∏–π](https://docs.ultralytics.com/ru/) | [Deutsch](https://docs.ultralytics.com/de/) | [Fran√ßais](https://docs.ultralytics.com/fr/) | [Espa√±ol](https://docs.ultralytics.com/es/) | [Portugu√™s](https://docs.ultralytics.com/pt/) | [ÿßŸÑÿπÿ±ÿ®Ÿäÿ©](https://docs.ultralytics.com/ar/)\n",
        "\n",
        "  <a href=\"https://bit.ly/yolov5-paperspace-notebook\"><img src=\"https://assets.paperspace.io/img/gradient-badge.svg\" alt=\"Run on Gradient\"></a>\n",
        "  <a href=\"https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
        "  <a href=\"https://www.kaggle.com/models/ultralytics/yolov5\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open In Kaggle\"></a>\n",
        "\n",
        "This <a href=\"https://github.com/ultralytics/yolov5\">YOLOv5</a> üöÄ notebook by <a href=\"https://ultralytics.com\">Ultralytics</a> presents simple train, validate and predict examples to help start your AI adventure.<br>We hope that the resources in this notebook will help you get the most out of YOLOv5. Please browse the YOLOv5 <a href=\"https://docs.ultralytics.com/yolov5\">Docs</a> for details, raise an issue on <a href=\"https://github.com/ultralytics/yolov5\">GitHub</a> for support, and join our <a href=\"https://ultralytics.com/discord\">Discord</a> community for questions and discussions!\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "# Setup\n",
        "\n",
        "Clone GitHub [repository](https://github.com/ultralytics/yolov5), install [dependencies](https://github.com/ultralytics/yolov5/blob/master/requirements.txt) and check PyTorch and GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbvMlHd_QwMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82073fc3-e369-463e-ad55-f227b10fb0e0"
      },
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt comet_ml  # install\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()  # checks"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 üöÄ v7.0-408-g3fee72b5 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete ‚úÖ (2 CPUs, 12.7 GB RAM, 41.3/112.6 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Verify files (replace with your path)\n",
        "!ls \"/content/drive/MyDrive/annotated_imgs\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbPtTFKn9Y4R",
        "outputId": "37e6d467-dc13-4c31-81c8-10b72266109a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "K1_msz.png  K3_msz.png\tK4_msz.png  T9_msz.png\tZ9_msz.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from skimage.segmentation import watershed\n",
        "from skimage.feature import peak_local_max\n",
        "from scipy import ndimage\n",
        "\n",
        "# Create directories if they don't exist\n",
        "!mkdir -p \"/content/drive/MyDrive/dataset/precise_labels\"\n",
        "!mkdir -p \"/content/drive/MyDrive/dataset/visualizations\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfvvALIQYWkS",
        "outputId": "e70094ea-7cb0-4e14-c0b7-8585caff3bce"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== MOUNT DRIVE & IMPORTS ==========\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from skimage.segmentation import watershed\n",
        "from skimage.feature import peak_local_max\n",
        "from scipy import ndimage\n",
        "import re\n",
        "\n",
        "# ========== CONFIGURATION ==========\n",
        "ANNOTATED_DIR = Path(\"/content/drive/MyDrive/annotated_imgs\")\n",
        "ORIGINAL_DIR = Path(\"/content/drive/MyDrive/dataset/originals\")\n",
        "OUTPUT_DIR = Path(\"/content/drive/MyDrive/dataset/precise_labels\")\n",
        "VISUAL_DIR = Path(\"/content/drive/MyDrive/dataset/visualizations\")\n",
        "\n",
        "# ========== ENHANCED SEGMENTATION PARAMETERS ==========\n",
        "INITIAL_HUE_TOLERANCE = 15    # Increased tolerance for color variation\n",
        "INITIAL_SAT_TOLERANCE = 25    # More lenient saturation matching\n",
        "GROWTH_STEPS = 5              # More growth iterations\n",
        "GROWTH_FACTOR = 1.8           # Progressive tolerance relaxation\n",
        "MIN_BACTERIA_AREA = 50        # pixels^2\n",
        "MAX_BACTERIA_AREA = 2000      # pixels^2\n",
        "\n",
        "# ========== UPDATED REGION GROWING WITH SAFE COORDINATE HANDLING ==========\n",
        "def adaptive_region_growing(annot_img, orig_img):\n",
        "    # Resize annotation to match original dimensions while preserving annotations\n",
        "    if annot_img.shape != orig_img.shape:\n",
        "        # First detect blue markers on original size\n",
        "        annot_hsv = cv2.cvtColor(annot_img, cv2.COLOR_BGR2HSV)\n",
        "        blue_mask = cv2.inRange(annot_hsv, np.array([90,70,70]), np.array([130,255,255]))\n",
        "        contours, _ = cv2.findContours(blue_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        # Calculate scaling factors\n",
        "        scale_x = orig_img.shape[1] / annot_img.shape[1]\n",
        "        scale_y = orig_img.shape[0] / annot_img.shape[0]\n",
        "\n",
        "        # Scale all contour points\n",
        "        scaled_contours = []\n",
        "        for cnt in contours:\n",
        "            scaled_cnt = cnt * np.array([scale_x, scale_y])\n",
        "            scaled_contours.append(scaled_cnt.astype(np.int32))\n",
        "\n",
        "        # Create new annotation image with correct size\n",
        "        new_annot = np.zeros_like(orig_img)\n",
        "        cv2.drawContours(new_annot, scaled_contours, -1, (255,0,0), -1)\n",
        "        annot_img = new_annot\n",
        "\n",
        "    # Rest of your processing remains the same...\n",
        "    hsv = cv2.cvtColor(orig_img, cv2.COLOR_BGR2HSV)\n",
        "    annot_hsv = cv2.cvtColor(annot_img, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # SAFE seed detection with boundary checks\n",
        "    blue_mask = cv2.inRange(annot_hsv, np.array([90,70,70]), np.array([130,255,255]))\n",
        "    seeds = []\n",
        "    contours, _ = cv2.findContours(blue_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    for cnt in contours:\n",
        "        M = cv2.moments(cnt)\n",
        "        if M[\"m00\"] > 0:\n",
        "            cX = min(max(int(M[\"m10\"] / M[\"m00\"]), 0), orig_img.shape[1]-1)\n",
        "            cY = min(max(int(M[\"m01\"] / M[\"m00\"]), 0), orig_img.shape[0]-1)\n",
        "            seeds.append((cX, cY))\n",
        "\n",
        "    # Create background mask\n",
        "    _, bg_mask = cv2.threshold(hsv[:,:,2], 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
        "    bg_mask = (bg_mask == 0).astype(np.uint8)\n",
        "\n",
        "    # Process each seed point\n",
        "    final_mask = np.zeros_like(hsv[:,:,0])\n",
        "    for seed in seeds:\n",
        "        # Relocate seed to optimal position\n",
        "        x, y = relocate_seed(seed, hsv, bg_mask, orig_img.shape)\n",
        "        h_ref, s_ref, _ = hsv[y, x]\n",
        "\n",
        "        # Multi-stage region growing\n",
        "        region = np.zeros_like(final_mask)\n",
        "        queue = [(x, y)]\n",
        "        visited = set()\n",
        "\n",
        "        for tolerance in np.linspace(1.0, GROWTH_FACTOR, GROWTH_STEPS):\n",
        "            h_tol = INITIAL_HUE_TOLERANCE * tolerance\n",
        "            s_tol = INITIAL_SAT_TOLERANCE * tolerance\n",
        "\n",
        "            while queue:\n",
        "                x, y = queue.pop(0)\n",
        "                if (x, y) in visited:\n",
        "                    continue\n",
        "                if not (0 <= x < orig_img.shape[1] and 0 <= y < orig_img.shape[0]):\n",
        "                    continue\n",
        "                if bg_mask[y, x]:\n",
        "                    continue\n",
        "\n",
        "                # Color similarity check with overflow protection\n",
        "                h, s, _ = hsv[y, x]\n",
        "                if abs(int(h) - int(h_ref)) < h_tol and abs(int(s) - int(s_ref)) < s_tol:\n",
        "                    region[y, x] = 255\n",
        "                    visited.add((x, y))\n",
        "\n",
        "                    # 8-way expansion\n",
        "                    for dx in [-1, 0, 1]:\n",
        "                        for dy in [-1, 0, 1]:\n",
        "                            if dx == 0 and dy == 0:\n",
        "                                continue\n",
        "                            nx, ny = x + dx, y + dy\n",
        "                            if (0 <= nx < orig_img.shape[1] and 0 <= ny < orig_img.shape[0]):\n",
        "                                queue.append((nx, ny))\n",
        "\n",
        "            # Morphological assistance in later stages\n",
        "            if tolerance > GROWTH_FACTOR/2:\n",
        "                region = cv2.dilate(region, np.ones((3,3), np.uint8))\n",
        "\n",
        "        final_mask = cv2.bitwise_or(final_mask, region)\n",
        "\n",
        "    # Post-processing\n",
        "    final_mask = cv2.morphologyEx(final_mask, cv2.MORPH_CLOSE,\n",
        "                                cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7,7)))\n",
        "\n",
        "    # Watershed for overlapping regions\n",
        "    distance = ndimage.distance_transform_edt(final_mask)\n",
        "    coords = peak_local_max(distance, min_distance=20, labels=final_mask)\n",
        "    markers = np.zeros_like(final_mask, dtype=np.int32)\n",
        "\n",
        "    for i, (x, y) in enumerate(coords):\n",
        "        markers[y, x] = i + 1\n",
        "\n",
        "    labels = watershed(-distance, markers, mask=final_mask)\n",
        "\n",
        "    # Extract validated contours\n",
        "    bacteria_contours = []\n",
        "    for label in np.unique(labels):\n",
        "        if label == 0:\n",
        "            continue\n",
        "\n",
        "        mask = np.zeros_like(labels, dtype=np.uint8)\n",
        "        mask[labels == label] = 255\n",
        "\n",
        "        cnts, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        for cnt in cnts:\n",
        "            area = cv2.contourArea(cnt)\n",
        "            if MIN_BACTERIA_AREA < area < MAX_BACTERIA_AREA:\n",
        "                bacteria_contours.append(cnt)\n",
        "\n",
        "    return bacteria_contours\n",
        "\n",
        "def relocate_seed(original_seed, hsv_img, bg_mask, img_shape):\n",
        "    x, y = original_seed\n",
        "    best_score = -np.inf\n",
        "    best_pos = (min(max(x, 0), img_shape[1]-1),\n",
        "                min(max(y, 0), img_shape[0]-1))\n",
        "\n",
        "    # Search in 15x15 window around original seed\n",
        "    for dx in range(-7, 8):\n",
        "        for dy in range(-7, 8):\n",
        "            nx = min(max(x + dx, 0), img_shape[1]-1)\n",
        "            ny = min(max(y + dy, 0), img_shape[0]-1)\n",
        "\n",
        "            if bg_mask[ny, nx]:\n",
        "                continue\n",
        "\n",
        "            # Score based on local color variation\n",
        "            window = hsv_img[max(0,ny-5):min(ny+6, img_shape[0]),\n",
        "                           max(0,nx-5):min(nx+6, img_shape[1])]\n",
        "            if window.size == 0:\n",
        "                continue\n",
        "\n",
        "            std_dev = np.std(window, axis=(0,1))\n",
        "            score = std_dev[0] + std_dev[1]  # Hue + Saturation variation\n",
        "\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_pos = (nx, ny)\n",
        "\n",
        "    return best_pos\n",
        "\n",
        "# ========== VISUALIZATION & OUTPUT ==========\n",
        "def process_image_pair(annot_path, orig_path):\n",
        "    # Load images\n",
        "    annot_img = cv2.imread(str(annot_path))\n",
        "    orig_img = cv2.imread(str(orig_path))\n",
        "\n",
        "    if annot_img is None or orig_img is None:\n",
        "        print(f\"‚ö†Ô∏è Error loading {annot_path.name} or {orig_path.name}\")\n",
        "        return\n",
        "\n",
        "    # Perform segmentation\n",
        "    contours = adaptive_region_growing(annot_img, orig_img)\n",
        "\n",
        "    # Create enhanced visualization\n",
        "    display_img = orig_img.copy()\n",
        "\n",
        "    # Draw filled contours with transparency\n",
        "    overlay = display_img.copy()\n",
        "    cv2.drawContours(overlay, contours, -1, (0,255,255), -1)  # Yellow fill\n",
        "    cv2.addWeighted(overlay, 0.3, display_img, 0.7, 0, display_img)\n",
        "\n",
        "    # Draw contour edges in contrasting color\n",
        "    cv2.drawContours(display_img, contours, -1, (255,0,255), 2)  # Purple edges\n",
        "\n",
        "    # Create comparison figure\n",
        "    fig, ax = plt.subplots(1, 3, figsize=(20, 6))\n",
        "    fig.suptitle(f\"Analysis for {orig_path.name}\", fontsize=16, y=0.95)\n",
        "\n",
        "    # Original Image\n",
        "    ax[0].imshow(cv2.cvtColor(orig_img, cv2.COLOR_BGR2RGB))\n",
        "    ax[0].set_title(\"Original Image\\n\", fontsize=12)\n",
        "    ax[0].axis('off')\n",
        "\n",
        "    # Annotation Points\n",
        "    blue_mask = cv2.inRange(cv2.cvtColor(annot_img, cv2.COLOR_BGR2HSV),\n",
        "                           np.array([90,70,70]), np.array([130,255,255]))\n",
        "    ax[1].imshow(blue_mask, cmap='Blues')\n",
        "    ax[1].set_title(f\"Annotation Points: {len(contours)}\\n\", fontsize=12)\n",
        "    ax[1].axis('off')\n",
        "\n",
        "    # Segmentation Result\n",
        "    ax[2].imshow(cv2.cvtColor(display_img, cv2.COLOR_BGR2RGB))\n",
        "    ax[2].set_title(f\"Segmented Bacteria: {len(contours)}\\n\", fontsize=12)\n",
        "    ax[2].axis('off')\n",
        "\n",
        "    plt.savefig(VISUAL_DIR / f\"{orig_path.stem}_seg.png\", bbox_inches='tight', dpi=150)\n",
        "    plt.close()\n",
        "\n",
        "    # Save YOLO OBB format labels\n",
        "    save_yolo_labels(orig_img.shape, contours, orig_path.stem)\n",
        "\n",
        "def save_yolo_labels(img_shape, contours, stem):\n",
        "    height, width = img_shape[:2]\n",
        "    with open(OUTPUT_DIR / f\"{stem}.txt\", \"w\") as f:\n",
        "        for cnt in contours:\n",
        "            # Get rotated bounding box\n",
        "            rect = cv2.minAreaRect(cnt)\n",
        "            box = cv2.boxPoints(rect)\n",
        "            box_norm = box / np.array([width, height])\n",
        "\n",
        "            # YOLO OBB format: class x1 y1 x2 y2 x3 y3 x4 y4\n",
        "            line = f\"0 \" + \" \".join([f\"{p[0]:.6f} {p[1]:.6f}\" for p in box_norm])\n",
        "            f.write(line + \"\\n\")\n",
        "\n",
        "# ========== GENERIC FILE HANDLING ==========\n",
        "def find_matching_pairs(annotated_dir, original_dir):\n",
        "    \"\"\"Matches any files with pattern: <name>_msz.<ext> to <name>.<ext>\"\"\"\n",
        "    pattern = re.compile(r'^(.+)_msz(\\.[a-zA-Z]+)$', re.IGNORECASE)\n",
        "    pairs = []\n",
        "\n",
        "    for annot_path in annotated_dir.glob('*'):\n",
        "        match = pattern.match(annot_path.name)\n",
        "        if match:\n",
        "            base_name = match.group(1) + match.group(2)\n",
        "            orig_path = original_dir / base_name\n",
        "            if orig_path.exists():\n",
        "                pairs.append((annot_path, orig_path))\n",
        "            else:\n",
        "                print(f\"‚ö†Ô∏è Missing original for {annot_path.name}\")\n",
        "    return pairs\n",
        "\n",
        "# ========== MAIN EXECUTION ==========\n",
        "def main():\n",
        "    # Setup directories\n",
        "    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    VISUAL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Find all valid image pairs\n",
        "    pairs = find_matching_pairs(ANNOTATED_DIR, ORIGINAL_DIR)\n",
        "\n",
        "    if not pairs:\n",
        "        print(\"‚ùå No valid image pairs found!\")\n",
        "        print(\"Ensure annotated files follow <name>_msz.<ext> pattern\")\n",
        "        return\n",
        "\n",
        "    processed = 0\n",
        "    for annot_path, orig_path in pairs:\n",
        "        try:\n",
        "            process_image_pair(annot_path, orig_path)\n",
        "            processed += 1\n",
        "            print(f\"‚úÖ Processed {orig_path.name}\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error processing {orig_path.name}: {str(e)}\")\n",
        "\n",
        "    print(f\"\\nüéâ Finished! Processed {processed}/{len(pairs)} image pairs\")\n",
        "    print(f\"Labels saved to: {OUTPUT_DIR}\")\n",
        "    print(f\"Visualizations saved to: {VISUAL_DIR}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Br9EymrcYXip",
        "outputId": "77f886f9-15cf-402f-aa30-9a39a282f82b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clear previous outputs (optional)\n",
        "!rm -rf \"/content/drive/MyDrive/dataset/precise_labels/*\"\n",
        "!rm -rf \"/content/drive/MyDrive/dataset/visualizations/*\"\n",
        "\n",
        "# Execute\n",
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2pXSaACbqy7",
        "outputId": "7dda10f7-a403-4add-d754-68936302ae68"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (1.14.1)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (3.4.2)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (11.1.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2025.3.13)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (0.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "‚ùå Error processing K4.png: index 1800 is out of bounds for axis 0 with size 1536\n",
            "‚ùå Error processing T9.png: index 1978 is out of bounds for axis 0 with size 1536\n",
            "‚ùå Error processing K1.png: index 1653 is out of bounds for axis 0 with size 1536\n",
            "‚ùå Error processing Z9.png: index 1682 is out of bounds for axis 0 with size 1536\n",
            "‚ùå Error processing K3.png: index 1797 is out of bounds for axis 0 with size 1536\n",
            "\n",
            "üéâ Finished! Processed 0/5 image pairs\n",
            "Labels saved to: /content/drive/MyDrive/dataset/precise_labels\n",
            "Visualizations saved to: /content/drive/MyDrive/dataset/visualizations\n"
          ]
        }
      ]
    }
  ]
}