{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLOv5 Tutorial",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6MPjfT5NrKQ"
      },
      "source": [
        "<div align=\"center\">\n",
        "\n",
        "  <a href=\"https://ultralytics.com/yolov5\" target=\"_blank\">\n",
        "    <img width=\"1024\", src=\"https://raw.githubusercontent.com/ultralytics/assets/main/yolov5/v70/splash.png\"></a>\n",
        "\n",
        "[‰∏≠Êñá](https://docs.ultralytics.com/zh/) | [ÌïúÍµ≠Ïñ¥](https://docs.ultralytics.com/ko/) | [Êó•Êú¨Ë™û](https://docs.ultralytics.com/ja/) | [–†—É—Å—Å–∫–∏–π](https://docs.ultralytics.com/ru/) | [Deutsch](https://docs.ultralytics.com/de/) | [Fran√ßais](https://docs.ultralytics.com/fr/) | [Espa√±ol](https://docs.ultralytics.com/es/) | [Portugu√™s](https://docs.ultralytics.com/pt/) | [ÿßŸÑÿπÿ±ÿ®Ÿäÿ©](https://docs.ultralytics.com/ar/)\n",
        "\n",
        "  <a href=\"https://bit.ly/yolov5-paperspace-notebook\"><img src=\"https://assets.paperspace.io/img/gradient-badge.svg\" alt=\"Run on Gradient\"></a>\n",
        "  <a href=\"https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
        "  <a href=\"https://www.kaggle.com/models/ultralytics/yolov5\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open In Kaggle\"></a>\n",
        "\n",
        "This <a href=\"https://github.com/ultralytics/yolov5\">YOLOv5</a> üöÄ notebook by <a href=\"https://ultralytics.com\">Ultralytics</a> presents simple train, validate and predict examples to help start your AI adventure.<br>We hope that the resources in this notebook will help you get the most out of YOLOv5. Please browse the YOLOv5 <a href=\"https://docs.ultralytics.com/yolov5\">Docs</a> for details, raise an issue on <a href=\"https://github.com/ultralytics/yolov5\">GitHub</a> for support, and join our <a href=\"https://ultralytics.com/discord\">Discord</a> community for questions and discussions!\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "# Setup\n",
        "\n",
        "Clone GitHub [repository](https://github.com/ultralytics/yolov5), install [dependencies](https://github.com/ultralytics/yolov5/blob/master/requirements.txt) and check PyTorch and GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbvMlHd_QwMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6963a8f-3c12-42d6-c9c6-ccb7abb35134"
      },
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt comet_ml  # install\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()  # checks"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 üöÄ v7.0-409-ge9ab205e Python-3.11.11 torch-2.6.0+cu124 CPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete ‚úÖ (2 CPUs, 12.7 GB RAM, 41.3/107.7 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Verify files (replace with your path)\n",
        "!ls \"/content/drive/MyDrive/annotated_imgs\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbPtTFKn9Y4R",
        "outputId": "c8b398f0-6090-4c84-8d2c-cb85fb8d9757"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "K1_msz.png  K3_msz.png\tK4_msz.png  T9_msz.png\tZ9_msz.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add this before training:\n",
        "!wget https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s-seg.pt"
      ],
      "metadata": {
        "id": "oHTK46nFz7Tz",
        "outputId": "81cc4853-3fc9-4035-cc2a-09654a8ca1bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-28 12:52:37--  https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s-seg.pt\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/264818686/11a51425-536d-402d-919d-d933efbde7fa?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250328%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250328T125237Z&X-Amz-Expires=300&X-Amz-Signature=53ed6102f4df7f472fbd3da00cc96d2dba9dfeaa5836ffbeeefcd976fc2c0354&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dyolov5s-seg.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-03-28 12:52:37--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/264818686/11a51425-536d-402d-919d-d933efbde7fa?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250328%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250328T125237Z&X-Amz-Expires=300&X-Amz-Signature=53ed6102f4df7f472fbd3da00cc96d2dba9dfeaa5836ffbeeefcd976fc2c0354&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dyolov5s-seg.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15593297 (15M) [application/octet-stream]\n",
            "Saving to: ‚Äòyolov5s-seg.pt.1‚Äô\n",
            "\n",
            "yolov5s-seg.pt.1    100%[===================>]  14.87M  67.9MB/s    in 0.2s    \n",
            "\n",
            "2025-03-28 12:52:37 (67.9 MB/s) - ‚Äòyolov5s-seg.pt.1‚Äô saved [15593297/15593297]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== MOUNT DRIVE & IMPORTS ==========\n",
        "from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from skimage.segmentation import watershed\n",
        "from skimage.feature import peak_local_max\n",
        "from scipy import ndimage\n",
        "import re\n",
        "\n",
        "# ========== CONFIGURATION ==========\n",
        "ANNOTATED_DIR = Path(\"/content/drive/MyDrive/annotated_imgs\")\n",
        "ORIGINAL_DIR = Path(\"/content/drive/MyDrive/dataset/originals\")\n",
        "OUTPUT_DIR = Path(\"/content/drive/MyDrive/dataset/precise_labels\")\n",
        "VISUAL_DIR = Path(\"/content/drive/MyDrive/dataset/visualizations\")\n",
        "\n",
        "# ========== ULTRA-OPTIMIZED PARAMETERS ==========\n",
        "# Annotation Detection\n",
        "BLUE_LOWER = np.array([75, 35, 35])  # Even wider blue range\n",
        "BLUE_UPPER = np.array([145, 255, 255])\n",
        "MIN_DOT_AREA = 5                     # Smaller minimum dot size\n",
        "MAX_DOT_AREA = 500                   # Larger maximum dot size\n",
        "\n",
        "# Region Growing (Aggressive settings)\n",
        "GROWTH_STEPS = 20                    # More growth phases\n",
        "GROWTH_FACTOR = 3.7                  # Faster tolerance relaxation\n",
        "NEIGHBORHOOD_SIZE = 20               # Larger search area for seed relocation\n",
        "BASE_TOL = 60                        # Initial tolerance for hue and sat\n",
        "BASE_VAL_TOL = 60                    # Tighter initial tolerance for value\n",
        "ALPHA = 2.6                          # Aggressiveness factor for faster relaxation\n",
        "BETA = 0.55                          # Slower relaxation for V\n",
        "\n",
        "# Post-processing\n",
        "MORPH_KERNEL_SIZE = 8                # Larger kernel for better hole filling\n",
        "MIN_DISTANCE_WATERSHED = 18          # Reduced minimum distance\n",
        "MIN_BACTERIA_AREA = 10               # Smaller minimum bacteria size\n",
        "MAX_BACTERIA_AREA = 5000             # Larger maximum bacteria size\n",
        "\n",
        "# ========== CORE FUNCTIONS ==========\n",
        "def detect_annotations(annot_img):\n",
        "    \"\"\"Enhanced blue dot detection with size filtering\"\"\"\n",
        "    hsv = cv2.cvtColor(annot_img, cv2.COLOR_BGR2HSV)\n",
        "    blue_mask = cv2.inRange(hsv, BLUE_LOWER, BLUE_UPPER)\n",
        "\n",
        "    # Enhance dots\n",
        "    kernel = np.ones((5,5), np.uint8)\n",
        "    blue_mask = cv2.morphologyEx(blue_mask, cv2.MORPH_CLOSE, kernel)\n",
        "    blue_mask = cv2.dilate(blue_mask, kernel, iterations=1)\n",
        "\n",
        "    # Find and filter contours\n",
        "    contours, _ = cv2.findContours(blue_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    annotations = []\n",
        "    for cnt in contours:\n",
        "        area = cv2.contourArea(cnt)\n",
        "        if MIN_DOT_AREA < area < MAX_DOT_AREA:\n",
        "            M = cv2.moments(cnt)\n",
        "            if M[\"m00\"] > 0:\n",
        "                cX = int(M[\"m10\"] / M[\"m00\"])\n",
        "                cY = int(M[\"m01\"] / M[\"m00\"])\n",
        "                annotations.append((cX, cY))\n",
        "\n",
        "    # Debug output\n",
        "    print(f\"Detected {len(annotations)} annotation points\")\n",
        "    return annotations\n",
        "\n",
        "# ========== ENHANCED SEED RELOCATION ==========\n",
        "def relocate_seed(seed, hsv_img, bg_mask, img_shape):\n",
        "    width, height = img_shape[1], img_shape[0]\n",
        "    x, y = np.clip(seed[0], 0, width-1), np.clip(seed[1], 0, height-1)\n",
        "    best_score = -np.inf\n",
        "    best_pos = (x, y)\n",
        "\n",
        "    avg_brightness = np.mean(hsv_img[: ,: ,2])\n",
        "    if avg_brightness < 100:\n",
        "        w_hue = 0.1\n",
        "        w_sat = 0.2\n",
        "        w_val = 0.7\n",
        "    else:\n",
        "        w_hue = 0.2\n",
        "        w_sat = 0.3\n",
        "        w_val = 0.5\n",
        "    if avg_brightness < 80:\n",
        "        w_val = 0.8\n",
        "        w_sat = 0.1\n",
        "        w_val = 0.1\n",
        "\n",
        "    # Larger search neighborhood\n",
        "    for dx in range(-NEIGHBORHOOD_SIZE, NEIGHBORHOOD_SIZE+1):\n",
        "        for dy in range(-NEIGHBORHOOD_SIZE, NEIGHBORHOOD_SIZE+1):\n",
        "            nx = np.clip(x + dx, 0, width-1)\n",
        "            ny = np.clip(y + dy, 0, height-1)\n",
        "\n",
        "            if bg_mask[ny, nx]: continue\n",
        "\n",
        "            # Larger window for better context\n",
        "            y1, y2 = max(0, ny-7), min(ny+8, height)\n",
        "            x1, x2 = max(0, nx-7), min(nx+8, width)\n",
        "            window = hsv_img[y1:y2, x1:x2]\n",
        "\n",
        "            if window.size == 0: continue\n",
        "\n",
        "            std_dev = np.std(window, axis=(0,1))\n",
        "            score = std_dev[0] * 3 + std_dev[1]  # Weighted towards hue\n",
        "            score = (std_dev[0] * w_hue) + (std_dev[1] * w_sat) + (std_dev[2] * w_val)\n",
        "\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_pos = (nx, ny)\n",
        "\n",
        "    return best_pos\n",
        "\n",
        "# ========== SUPERCHARGED REGION GROWING ==========\n",
        "def adaptive_region_growing(annot_img, orig_img):\n",
        "    # Resize annotation if needed\n",
        "    if annot_img.shape[:2] != orig_img.shape[:2]:\n",
        "        annot_img = cv2.resize(annot_img, (orig_img.shape[1], orig_img.shape[0]),\n",
        "                             interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "    # Enhanced annotation detection\n",
        "    annotations = detect_annotations(annot_img)\n",
        "    if not annotations:\n",
        "        print(\"‚ö†Ô∏è No annotations detected!\")\n",
        "        return []\n",
        "\n",
        "    # Convert to HSV and create background mask\n",
        "    hsv = cv2.cvtColor(orig_img, cv2.COLOR_BGR2HSV)\n",
        "    _, bg_mask = cv2.threshold(hsv[:,:,2], 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
        "    bg_mask = (bg_mask == 0).astype(np.uint8)\n",
        "\n",
        "    # calculating avg brightness\n",
        "    avg_brightness = np.mean(hsv[: ,: ,2])\n",
        "    if avg_brightness < 100:\n",
        "      w_hue = 0.1\n",
        "      w_sat = 0.2\n",
        "      w_val = 0.7\n",
        "    else:\n",
        "      w_hue = 0.2\n",
        "      w_sat = 0.3\n",
        "      w_val = 0.5\n",
        "\n",
        "    # Supercharged region growing\n",
        "    final_mask = np.zeros_like(hsv[:,:,0], dtype=np.uint8)\n",
        "    for seed in annotations:\n",
        "        best_seed = relocate_seed(seed, hsv, bg_mask, orig_img.shape)\n",
        "        h_ref, s_ref, v_ref = hsv[best_seed[1], best_seed[0]]\n",
        "        region = np.zeros_like(final_mask)\n",
        "        queue = [best_seed]\n",
        "        visited = set()\n",
        "\n",
        "        for tolerance in np.linspace(1.0, GROWTH_FACTOR, GROWTH_STEPS):\n",
        "            tol = BASE_TOL * (1 + ALPHA * (tolerance/GROWTH_STEPS))\n",
        "            val_tol = BASE_VAL_TOL * (1 + BETA * (tolerance/GROWTH_STEPS))\n",
        "\n",
        "            while queue:\n",
        "                x, y = queue.pop(0)\n",
        "                x = np.clip(x, 0, orig_img.shape[1]-1)\n",
        "                y = np.clip(y, 0, orig_img.shape[0]-1)\n",
        "\n",
        "                if (x, y) in visited: continue\n",
        "                if bg_mask[y, x]: continue\n",
        "\n",
        "                h, s, v = hsv[y, x]\n",
        "                hue_diff = min(abs(h - h_ref), 180 - abs(h - h_ref))\n",
        "                sat_diff = abs(s - s_ref)\n",
        "                val_diff = abs(v - v_ref)\n",
        "\n",
        "                # Dynamic adaptive thresholding\n",
        "\n",
        "                if (w_hue * hue_diff + w_sat * sat_diff) < tol and w_val * val_diff < val_tol:\n",
        "                #if (0.6 * hue_diff + 0.4 * sat_diff) < h_tol:\n",
        "                    region[y, x] = 255\n",
        "                    visited.add((x, y))\n",
        "\n",
        "                    # 8-way expansion with probabilistic sampling\n",
        "                    neighbors = [(x+dx, y+dy) for dx in [-1,0,1] for dy in [-1,0,1] if dx != 0 or dy != 0]\n",
        "                    np.random.shuffle(neighbors)\n",
        "                    for nx, ny in neighbors:\n",
        "                        nx = np.clip(nx, 0, orig_img.shape[1]-1)\n",
        "                        ny = np.clip(ny, 0, orig_img.shape[0]-1)\n",
        "                        if (nx, ny) not in visited:\n",
        "                            queue.append((nx, ny))\n",
        "\n",
        "        # Add morphological assistance during growth\n",
        "        region = cv2.dilate(region, np.ones((3,3), np.uint8))\n",
        "        final_mask = cv2.bitwise_or(final_mask, region)\n",
        "\n",
        "    # Aggressive post-processing\n",
        "    final_mask = cv2.morphologyEx(final_mask, cv2.MORPH_CLOSE,\n",
        "                                cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (MORPH_KERNEL_SIZE,MORPH_KERNEL_SIZE)))\n",
        "    final_mask = cv2.dilate(final_mask, np.ones((5,5), np.uint8), iterations=1)\n",
        "\n",
        "    # More permissive watershed\n",
        "    distance = ndimage.distance_transform_edt(final_mask)\n",
        "    #distance = cv2.GaussianBlur(distance, (5, 5), 0)\n",
        "    coords = peak_local_max(distance, min_distance=MIN_DISTANCE_WATERSHED,\n",
        "                           threshold_rel=0.3, labels=final_mask)\n",
        "\n",
        "    markers = np.zeros_like(final_mask, dtype=np.int32)\n",
        "    for i, (y, x) in enumerate(coords):\n",
        "        if 0 <= x < orig_img.shape[1] and 0 <= y < orig_img.shape[0]:\n",
        "            markers[y, x] = i + 1\n",
        "\n",
        "    labels = watershed(-distance, markers, mask=final_mask)\n",
        "\n",
        "    # Extract contours with relaxed criteria\n",
        "    bacteria_contours = []\n",
        "    for label in np.unique(labels):\n",
        "        if label == 0: continue\n",
        "\n",
        "        mask = np.zeros_like(labels, dtype=np.uint8)\n",
        "        mask[labels == label] = 255\n",
        "\n",
        "        cnts, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        for cnt in cnts:\n",
        "            area = cv2.contourArea(cnt)\n",
        "            if MIN_BACTERIA_AREA < area < MAX_BACTERIA_AREA:\n",
        "                bacteria_contours.append(cnt)\n",
        "\n",
        "    return bacteria_contours\n",
        "\n",
        "\n",
        "# ========== ENHANCED VISUALIZATION ==========\n",
        "def process_image_pair(annot_path, orig_path):\n",
        "    # Load images\n",
        "    annot_img = cv2.imread(str(annot_path))\n",
        "    orig_img = cv2.imread(str(orig_path))\n",
        "\n",
        "    if annot_img is None or orig_img is None:\n",
        "        print(f\"‚ö†Ô∏è Error loading {annot_path.name} or {orig_path.name}\")\n",
        "        return\n",
        "\n",
        "    # Get annotation count BEFORE processing\n",
        "    blue_mask = cv2.inRange(cv2.cvtColor(annot_img, cv2.COLOR_BGR2HSV),\n",
        "                           BLUE_LOWER, BLUE_UPPER)\n",
        "    annot_contours, _ = cv2.findContours(blue_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    annotation_count = len([c for c in annot_contours if MIN_DOT_AREA < cv2.contourArea(c) < MAX_DOT_AREA])\n",
        "\n",
        "    # Perform segmentation\n",
        "    contours = adaptive_region_growing(annot_img, orig_img)\n",
        "\n",
        "    # Create visualization\n",
        "    display_img = orig_img.copy()\n",
        "    overlay = display_img.copy()\n",
        "    cv2.drawContours(overlay, contours, -1, (0,255,255), -1)  # Yellow fill\n",
        "    cv2.addWeighted(overlay, 0.3, display_img, 0.7, 0, display_img)\n",
        "    cv2.drawContours(display_img, contours, -1, (255,0,255), 2)  # Purple edges\n",
        "\n",
        "    # Create comparison figure with improved titles\n",
        "    fig, ax = plt.subplots(1, 3, figsize=(20, 6))\n",
        "    fig.suptitle(f\"Analysis for {orig_path.name}\", fontsize=16, y=0.95)\n",
        "\n",
        "    # Original Image\n",
        "    ax[0].imshow(cv2.cvtColor(annot_img, cv2.COLOR_BGR2RGB))\n",
        "    ax[0].set_title(\"Original Image\\n\", fontsize=12)\n",
        "    ax[0].axis('off')\n",
        "\n",
        "    # Annotation Points - Now shows actual annotation count\n",
        "    ax[1].imshow(blue_mask, cmap='gray')\n",
        "    ax[1].set_title(f\"Annotation Points: {annotation_count}\\n\", fontsize=12)  # Changed to annotation_count\n",
        "    ax[1].axis('off')\n",
        "\n",
        "    # Segmentation Result\n",
        "    ax[2].imshow(cv2.cvtColor(display_img, cv2.COLOR_BGR2RGB))\n",
        "    ax[2].set_title(f\"Segmented Bacteria: {len(contours)}\\n\", fontsize=12)\n",
        "    ax[2].axis('off')\n",
        "\n",
        "    plt.savefig(VISUAL_DIR / f\"{orig_path.stem}_seg.png\", bbox_inches='tight', dpi=150)\n",
        "    plt.close()\n",
        "\n",
        "    # Save labels\n",
        "    save_yolo_labels(orig_img.shape, contours, orig_path.stem)\n",
        "\n",
        "    # return segmented bacteria count\n",
        "    return len(contours)\n",
        "\n",
        "def save_yolo_labels(img_shape, contours, stem):\n",
        "    height, width = img_shape[:2]\n",
        "    with open(OUTPUT_DIR / f\"{stem}.txt\", \"w\") as f:\n",
        "        for cnt in contours:\n",
        "            rect = cv2.minAreaRect(cnt)\n",
        "            box = cv2.boxPoints(rect)\n",
        "            box_norm = box / np.array([width, height])\n",
        "            line = f\"0 \" + \" \".join([f\"{p[0]:.6f} {p[1]:.6f}\" for p in box_norm])\n",
        "            f.write(line + \"\\n\")\n",
        "\n",
        "def find_matching_pairs(annotated_dir, original_dir):\n",
        "    pattern = re.compile(r'^(.+)_msz(\\.[a-zA-Z]+)$', re.IGNORECASE)\n",
        "    pairs = []\n",
        "    for annot_path in annotated_dir.glob('*'):\n",
        "        match = pattern.match(annot_path.name)\n",
        "        if match:\n",
        "            base_name = match.group(1) + match.group(2)\n",
        "            orig_path = original_dir / base_name\n",
        "            if orig_path.exists():\n",
        "                pairs.append((annot_path, orig_path))\n",
        "            else:\n",
        "                print(f\"‚ö†Ô∏è Missing original for {annot_path.name}\")\n",
        "    return pairs\n",
        "\n",
        "def main():\n",
        "    # Setup directories\n",
        "    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    VISUAL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Find all valid image pairs\n",
        "    pairs = find_matching_pairs(ANNOTATED_DIR, ORIGINAL_DIR)\n",
        "\n",
        "    if not pairs:\n",
        "        print(\"‚ùå No valid image pairs found!\")\n",
        "        print(\"Ensure annotated files follow _msz. pattern\")\n",
        "        return\n",
        "\n",
        "    processed = 0\n",
        "    for annot_path, orig_path in pairs:\n",
        "        try:\n",
        "            segmented_bacteria_count = process_image_pair(annot_path, orig_path)\n",
        "            processed += 1\n",
        "            print(f\"‚úÖ Processed {orig_path.name} - Found {segmented_bacteria_count} bacterias\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error processing {orig_path.name}: {str(e)}\")\n",
        "\n",
        "    print(f\"\\nüéâ Finished! Processed {processed}/{len(pairs)} image pairs\")\n",
        "    print(f\"Labels saved to: {OUTPUT_DIR}\")\n",
        "    print(f\"Visualizations saved to: {VISUAL_DIR}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # Clear previous outputs (optional)\n",
        "    !rm -rf \"/content/drive/MyDrive/dataset/precise_labels/*\"\n",
        "    !rm -rf \"/content/drive/MyDrive/dataset/visualizations/*\"\n",
        "\n",
        "    # Run the processing\n",
        "    main()\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Br9EymrcYXip",
        "outputId": "91b3f0de-9673-409c-b70f-e404b6244713"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected 63 annotation points\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-92-327486c3e705>:168: RuntimeWarning: overflow encountered in scalar subtract\n",
            "  val_diff = abs(v - v_ref)\n",
            "<ipython-input-92-327486c3e705>:167: RuntimeWarning: overflow encountered in scalar subtract\n",
            "  sat_diff = abs(s - s_ref)\n",
            "<ipython-input-92-327486c3e705>:166: RuntimeWarning: overflow encountered in scalar subtract\n",
            "  hue_diff = min(abs(h - h_ref), 180 - abs(h - h_ref))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Processed K4.png - Found 49 bacterias\n",
            "Detected 36 annotation points\n",
            "‚úÖ Processed T9.png - Found 15 bacterias\n",
            "Detected 64 annotation points\n",
            "‚úÖ Processed K1.png - Found 57 bacterias\n",
            "Detected 25 annotation points\n",
            "‚úÖ Processed Z9.png - Found 24 bacterias\n",
            "Detected 51 annotation points\n",
            "‚úÖ Processed K3.png - Found 46 bacterias\n",
            "\n",
            "üéâ Finished! Processed 5/5 image pairs\n",
            "Labels saved to: /content/drive/MyDrive/dataset/precise_labels\n",
            "Visualizations saved to: /content/drive/MyDrive/dataset/visualizations\n"
          ]
        }
      ]
    }
  ]
}